{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_label = []\n",
    "for _ in range(50):\n",
    "    start = random.randint(0, 97)  # Random start to generate diverse sequences\n",
    "    seq = [start, start+1, start+2]\n",
    "    train_data.append(seq)\n",
    "    train_label.append(start+3)  # Next number in sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "[72, 73, 74]\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(train_label))\n",
    "print(train_data[1])\n",
    "print(train_label[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 3, 1])\n",
      "torch.Size([50])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleRNN(\n",
       "  (rnn): RNN(1, 16, batch_first=True)\n",
       "  (linear): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X = torch.FloatTensor(train_data).unsqueeze(-1)  # Shape: [50, 3, 1]\n",
    "print(X.shape)\n",
    "y = torch.FloatTensor(train_label)\n",
    "print(y.shape)\n",
    "\n",
    "# Simple RNN model\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size=1, hidden_size=16, batch_first=True)\n",
    "        self.linear = nn.Linear(16, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output, _ = self.rnn(x)\n",
    "        return self.linear(output[:, -1, :]).squeeze()\n",
    "\n",
    "# Create and train model\n",
    "model = SimpleRNN()\n",
    "# summary(model, (50, 3, 1))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 3184.6130\n",
      "Epoch: 100 | Loss: 1836.0853\n",
      "Epoch: 200 | Loss: 1078.7091\n",
      "Epoch: 300 | Loss: 645.6280\n",
      "Epoch: 400 | Loss: 395.2435\n",
      "Epoch: 500 | Loss: 251.8957\n",
      "Epoch: 600 | Loss: 166.3913\n",
      "Epoch: 700 | Loss: 114.6052\n",
      "Epoch: 800 | Loss: 81.7485\n",
      "Epoch: 900 | Loss: 59.2929\n",
      "Epoch: 1000 | Loss: 42.8959\n",
      "Epoch: 1100 | Loss: 30.7801\n",
      "Epoch: 1200 | Loss: 21.9459\n",
      "Epoch: 1300 | Loss: 15.6746\n",
      "Epoch: 1400 | Loss: 11.1456\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "for epoch in range(1500):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    prediction = model(X)\n",
    "    loss = loss_fn(prediction, y)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch: {epoch} | Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sequence [7, 8, 9] -> Predicted: 10.0014, Rounded pred: 10.0 Expected: 10\n",
      "\n",
      "Sequence [11, 12, 13] -> Predicted: 13.7659, Rounded pred: 14.0 Expected: 14\n",
      "\n",
      "Sequence [20, 21, 22] -> Predicted: 22.9745, Rounded pred: 23.0 Expected: 23\n",
      "\n",
      "Sequence [50, 51, 52] -> Predicted: 52.9788, Rounded pred: 53.0 Expected: 53\n",
      "\n",
      "Sequence [143, 144, 145] -> Predicted: 87.3655, Rounded pred: 87.0 Expected: 146\n"
     ]
    }
   ],
   "source": [
    "# Test several sequences\n",
    "test_sequences = [\n",
    "    [7,8,9],\n",
    "    [11,12,13],\n",
    "    [20,21,22],\n",
    "    [50, 51, 52],\n",
    "    [143, 144, 145],\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for seq in test_sequences:\n",
    "        test_input = torch.FloatTensor(seq).reshape(1, 3, 1)\n",
    "        pred = model(test_input)\n",
    "        print(f'\\nSequence {seq} -> Predicted: {pred.item():.4f}, Rounded pred: {np.round(pred)} Expected: {seq[-1]+1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://www.tensorflow.org/text/guide/word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import kagglehub\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /root/.cache/kagglehub/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/versions/1\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probably want to change the name of the directory w/ \"mv IMDB Dataset.csv dataset.csv\" \n",
    "# Change to your directory\n",
    "path = '/root/.cache/kagglehub/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews/versions/1/IMDB Dataset.csv'\n",
    "os.path.isfile(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "(50000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.&lt;br /&gt;&lt;br /&gt;The first thing that struck me...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire p...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue i...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet &amp; his parents are fighting all the time.&lt;br /&gt;&lt;br /&gt;This movie is slower than a soap opera... and suddenl...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what mone...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                    review  \\\n",
       "0  One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me...   \n",
       "1  A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire p...   \n",
       "2  I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue i...   \n",
       "3  Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenl...   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what mone...   \n",
       "\n",
       "  sentiment  \n",
       "0  positive  \n",
       "1  positive  \n",
       "2  positive  \n",
       "3  negative  \n",
       "4  positive  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(path)\n",
    "print(len(dataset))\n",
    "print(dataset.shape)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'name', 'is', 'john', 'doe']\n"
     ]
    }
   ],
   "source": [
    "def tokenizer(text):\n",
    "\n",
    "    text = text.replace('<br />', ' ')\n",
    "    text = text.replace('<br/>', ' ')\n",
    "    text = text.replace('<br>', ' ')\n",
    "    text = text.lower()    \n",
    "    for punctuation in \".,!?:;:\":\n",
    "        text = text.replace(punctuation, f'') # Add space before and after the punctuation\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "text = \"My name is John Doe!\"\n",
    "print(tokenizer(text))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'of', 'the', 'other', 'reviewers', 'has', 'mentioned', 'that', 'after', 'watching', 'just', '1', 'oz', 'episode', \"you'll\", 'be', 'hooked', 'they', 'are', 'right', 'as', 'this', 'is', 'exactly', 'what', 'happened', 'with', 'me', 'the', 'first', 'thing', 'that', 'struck', 'me', 'about', 'oz', 'was', 'its', 'brutality', 'and', 'unflinching', 'scenes', 'of', 'violence', 'which', 'set', 'in', 'right', 'from', 'the', 'word', 'go', 'trust', 'me', 'this', 'is', 'not', 'a', 'show', 'for', 'the', 'faint', 'hearted', 'or', 'timid', 'this', 'show', 'pulls', 'no', 'punches', 'with', 'regards', 'to', 'drugs', 'sex', 'or', 'violence', 'its', 'is', 'hardcore', 'in', 'the', 'classic', 'use', 'of', 'the', 'word', 'it', 'is', 'called', 'oz', 'as', 'that', 'is', 'the', 'nickname', 'given', 'to', 'the', 'oswald', 'maximum', 'security', 'state', 'penitentary', 'it', 'focuses', 'mainly', 'on', 'emerald', 'city', 'an', 'experimental', 'section', 'of', 'the', 'prison', 'where', 'all', 'the', 'cells', 'have', 'glass', 'fronts', 'and', 'face', 'inwards', 'so', 'privacy', 'is', 'not', 'high', 'on', 'the', 'agenda', 'em', 'city', 'is', 'home', 'to', 'manyaryans', 'muslims', 'gangstas', 'latinos', 'christians', 'italians', 'irish', 'and', 'moreso', 'scuffles', 'death', 'stares', 'dodgy', 'dealings', 'and', 'shady', 'agreements', 'are', 'never', 'far', 'away', 'i', 'would', 'say', 'the', 'main', 'appeal', 'of', 'the', 'show', 'is', 'due', 'to', 'the', 'fact', 'that', 'it', 'goes', 'where', 'other', 'shows', \"wouldn't\", 'dare', 'forget', 'pretty', 'pictures', 'painted', 'for', 'mainstream', 'audiences', 'forget', 'charm', 'forget', 'romanceoz', \"doesn't\", 'mess', 'around', 'the', 'first', 'episode', 'i', 'ever', 'saw', 'struck', 'me', 'as', 'so', 'nasty', 'it', 'was', 'surreal', 'i', \"couldn't\", 'say', 'i', 'was', 'ready', 'for', 'it', 'but', 'as', 'i', 'watched', 'more', 'i', 'developed', 'a', 'taste', 'for', 'oz', 'and', 'got', 'accustomed', 'to', 'the', 'high', 'levels', 'of', 'graphic', 'violence', 'not', 'just', 'violence', 'but', 'injustice', '(crooked', 'guards', \"who'll\", 'be', 'sold', 'out', 'for', 'a', 'nickel', 'inmates', \"who'll\", 'kill', 'on', 'order', 'and', 'get', 'away', 'with', 'it', 'well', 'mannered', 'middle', 'class', 'inmates', 'being', 'turned', 'into', 'prison', 'bitches', 'due', 'to', 'their', 'lack', 'of', 'street', 'skills', 'or', 'prison', 'experience)', 'watching', 'oz', 'you', 'may', 'become', 'comfortable', 'with', 'what', 'is', 'uncomfortable', 'viewingthats', 'if', 'you', 'can', 'get', 'in', 'touch', 'with', 'your', 'darker', 'side']\n"
     ]
    }
   ],
   "source": [
    "sample_review = dataset['review'][0]\n",
    "print(tokenizer(sample_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def build_vocab(texts, max_words=10000):\n",
    "    word_counter = Counter()\n",
    "    for text in texts:\n",
    "        tokens = tokenizer(text)\n",
    "        word_counter.update(tokens)\n",
    "\n",
    "    vocab = ['<PAD>', '<UNK>']\n",
    "    vocab += [word for word, count in word_counter.most_common(max_words)]\n",
    "\n",
    "    word_to_idx = {word:idx for idx, word in enumerate(vocab)}\n",
    "    return word_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 10002\n",
      "<PAD>: 0\n",
      "<UNK>: 1\n",
      "the: 2\n",
      "a: 3\n",
      "and: 4\n",
      "of: 5\n",
      "to: 6\n",
      "is: 7\n",
      "in: 8\n",
      "it: 9\n"
     ]
    }
   ],
   "source": [
    "vocab = build_vocab(dataset['review'])\n",
    "print(\"Vocabulary size:\", len(vocab))\n",
    "vocab_20 = list(vocab.items())[:10]\n",
    "for word, idx in vocab_20:\n",
    "    print(f'{word}: {idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create custom dataset \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "class MovieReview(Dataset):\n",
    "    def __init__(self, reviews, labels, vocab, max_len=200):\n",
    "        self.reviews = list(reviews)\n",
    "        self.labels = list(labels) \n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        review = self.reviews[idx]\n",
    "        label = self.labels[idx]\n",
    "        tokens = tokenizer(review)[:self.max_len]\n",
    "\n",
    "        indices = [self.vocab.get(token, 1) for token in tokens] \n",
    "\n",
    "        if len(indices) < self.max_len:\n",
    "            indices += [0] * (self.max_len - len(indices))\n",
    "        \n",
    "        return {\n",
    "            'input_ids': torch.tensor(indices),\n",
    "            'labels': torch.tensor(1 if label == 'positive' else 0)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset['review'], dataset['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: 37500 x_test: 12500 y_train: 37500 y_test: 12500\n"
     ]
    }
   ],
   "source": [
    "print(f'x_train: {len(x_train)} x_test: {len(x_test)} y_train: {len(y_train)} y_test: {len(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MovieReview(x_train, y_train, vocab)\n",
    "test_dataset = MovieReview(x_test, y_test, vocab)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   2,  246, 9236,  ...,    2,  271, 1533],\n",
      "        [ 890,  184,    2,  ...,    0,    0,    0],\n",
      "        [  89,    5,   30,  ...,    9,   14,    3],\n",
      "        ...,\n",
      "        [   1,  558,  175,  ...,   72,   85,   34],\n",
      "        [  22,  115,   51,  ...,  102, 2669,  337],\n",
      "        [5852, 4948,    3,  ...,   10,  495,    1]])\n",
      "tensor([0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
      "        1, 1, 0, 0, 1, 1, 0, 1])\n",
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "sample_batch = next(iter(train_loader))\n",
    "print(sample_batch['input_ids'])\n",
    "print(sample_batch['labels'])\n",
    "print(sample_batch['labels'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentLSTM(\n",
       "  (embeddings): Embedding(10002, 200)\n",
       "  (lstm): LSTM(200, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (linear1): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SentimentLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=200, hidden_dim=256, n_layers=2):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, \n",
    "                            hidden_size=hidden_dim, \n",
    "                            num_layers=n_layers,\n",
    "                            batch_first=True, \n",
    "                            bidirectional=True)\n",
    "        \n",
    "        self.linear1 = nn.Linear(hidden_dim * 2, 1)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"Input shape:\", x.shape)\n",
    "\n",
    "        embedded = self.dropout(self.embeddings(x))\n",
    "        # print(\"Embedded shape:\", embedded.shape)\n",
    "\n",
    "\n",
    "        lstm_out, _ = self.lstm(embedded)\n",
    "\n",
    "        # print(f'lstm output shape: {lstm_out.shape}')\n",
    "\n",
    "        out = self.linear1(lstm_out[:, -1, :])\n",
    "        # print(\"Output shape:\", out.shape)\n",
    "\n",
    "\n",
    "        return torch.sigmoid(out)\n",
    "\n",
    "model = SentimentLSTM(vocab_size=len(vocab))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentimentRNN(\n",
       "  (embedding): Embedding(10002, 100)\n",
       "  (lstm): LSTM(100, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, device, train_loader, criterion, optimizer, epochs):\n",
    "    print(device)\n",
    "    model.to(device)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=\"training\"):\n",
    "            # Get data\n",
    "            inputs = batch['input_ids'].to(device)\n",
    "            labels = batch['labels'].float().to(device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.squeeze(1)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f'Epoch {epoch+1}, Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 1172/1172 [00:31<00:00, 36.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 1172/1172 [00:31<00:00, 36.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.6932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 1172/1172 [00:31<00:00, 37.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.6914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 1172/1172 [00:32<00:00, 35.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.6864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 1172/1172 [00:33<00:00, 35.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.5599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 1172/1172 [00:33<00:00, 35.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.3557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 1172/1172 [00:33<00:00, 35.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.2960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 1172/1172 [00:32<00:00, 35.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.2574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 1172/1172 [00:33<00:00, 35.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.2329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 1172/1172 [00:31<00:00, 37.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.2099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 1172/1172 [00:31<00:00, 36.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.1838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 1172/1172 [00:32<00:00, 35.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 0.1623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 1172/1172 [00:31<00:00, 37.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 0.1463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 1172/1172 [00:32<00:00, 36.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 0.1298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 1172/1172 [00:30<00:00, 37.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 0.1136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model, device, train_loader, criterion, optimizer, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = torch.load('model.pt', weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentimentRNN(\n",
       "  (embedding): Embedding(10002, 100)\n",
       "  (lstm): LSTM(100, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, device, test_loader, criterion):\n",
    "    print(device)\n",
    "    model.to(device)\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():  # No need to track gradients during testing\n",
    "        for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "            # Get data\n",
    "            inputs = batch['input_ids'].to(device)\n",
    "            labels = batch['labels'].float().to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.squeeze(1)  # Remove the extra dimension if needed\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            predicted = (outputs >= 0.5).float()  # For binary classification (threshold 0.5)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            total_predictions += labels.size(0)\n",
    "\n",
    "        avg_loss = total_loss / len(test_loader)  # Use test_loader for average loss\n",
    "        accuracy = (correct_predictions / total_predictions) * 100  # Accuracy in percentage\n",
    "        \n",
    "        print(f'Test Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 391/391 [00:03<00:00, 103.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3612, Accuracy: 88.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model(model_test, device, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, vocab, text, device, max_len=200):\n",
    "    # Step 1: Tokenize the input text\n",
    "    tokens = tokenizer(text)\n",
    "    \n",
    "    # Step 2: Convert tokens to indices using the vocabulary\n",
    "    indices = [vocab.get(token, 1) for token in tokens]  # 1 is for <UNK> token\n",
    "    \n",
    "    # Pad the input if necessary\n",
    "    if len(indices) < max_len:\n",
    "        indices += [0] * (max_len - len(indices))  # Pad with <PAD> token (0)\n",
    "    \n",
    "    # Convert the indices to a tensor\n",
    "    input_tensor = torch.tensor(indices).unsqueeze(0).to(device)  # Add batch dimension and move to the same device\n",
    "    \n",
    "    # Step 3: Run the model to get the prediction\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)  # Get the output logits\n",
    "    \n",
    "    # Step 4: Convert output to a class prediction\n",
    "    predicted_class = torch.round(output).item()  # 0 or 1\n",
    "    \n",
    "    # Step 5: Return the prediction result\n",
    "    return \"positive\" if predicted_class == 1 else \"negative\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: positive\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Check if GPU is available, otherwise use CPU\n",
    "text = \"The movie tickled my pickl\"\n",
    "prediction = predict(model, vocab, text, device)\n",
    "print(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nx)",
   "language": "python",
   "name": "nx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
