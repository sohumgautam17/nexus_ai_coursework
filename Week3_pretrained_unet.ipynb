{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn # This imports the neural network library (All the features we need are here)\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import monai\n",
    "from monai.losses import DiceLoss\n",
    "\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.Resize(512, 512),\n",
    "    ToTensorV2()\n",
    "], p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: data/VOCtrainval_11-May-2012.tar\n",
      "Extracting data/VOCtrainval_11-May-2012.tar to data\n"
     ]
    }
   ],
   "source": [
    "class VOCDataset(torchvision.datasets.VOCSegmentation):\n",
    "    def __getitem__(self, idx):\n",
    "        img, mask = super().__getitem__(idx)\n",
    "\n",
    "        # Convert to numpy arrays\n",
    "        image = np.array(img)\n",
    "        mask = np.array(mask)\n",
    "\n",
    "        # Apply transformations\n",
    "        transformed = transform(image=image, mask=mask)\n",
    "        image = transformed['image']\n",
    "        mask = transformed['mask']\n",
    "\n",
    "        # Normalize image\n",
    "        image = image.float() / 255.0\n",
    "\n",
    "        # Add channel dimension to mask [H, W] -> [1, H, W]\n",
    "        # No need for torch.from_numpy since mask is already a tensor\n",
    "        mask = mask.unsqueeze(0)\n",
    "\n",
    "        return image, mask.long()\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = VOCDataset(root='data', year='2012', image_set='train', download=True)\n",
    "val_dataset = VOCDataset(root='data', year='2012', image_set='trainval', download=True)\n",
    "\n",
    "# Test the shapes\n",
    "image, mask = train_dataset[0]\n",
    "print(\"Single sample shapes:\")\n",
    "print(f\"Image shape: {image.shape}\")    # Should be [3, 512, 512]\n",
    "print(f\"Mask shape: {mask.shape}\")      # Should be [1, 512, 512]\n",
    "print(f\"Unique mask values: {torch.unique(mask)}\")\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Test batch shapes\n",
    "batch_images, batch_masks = next(iter(train_dataloader))\n",
    "print(\"\\nBatch shapes:\")\n",
    "print(f\"Batch images shape: {batch_images.shape}\")  # Should be [4, 3, 512, 512]\n",
    "print(f\"Batch masks shape: {batch_masks.shape}\")    # Should be [4, 1, 512, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
